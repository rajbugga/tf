{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Extract schema names into a list\n",
    "schema_names = sqlContext.sql(\"SHOW DATABASES\").collect()\n",
    "schemas = [row.databaseName for row in schema_names]\n",
    "\n",
    "# Initialize an empty list for view definitions\n",
    "all_view_definitions = []\n",
    "\n",
    "for schema in schemas:\n",
    "    # Get all views in the current schema\n",
    "    views = sqlContext.sql(f\"SHOW VIEWS IN `{schema}`\").collect()\n",
    "\n",
    "    for view in views:\n",
    "        view_name = view.viewName\n",
    "        # Get the SQL command to create the view\n",
    "        view_definition = sqlContext.sql(f\"SHOW CREATE TABLE `{schema}`.`{view_name}`\").collect()\n",
    "\n",
    "        # Assuming view_definition returns a single row with a single column\n",
    "        if view_definition:\n",
    "            create_statement = view_definition[0][0]\n",
    "            all_view_definitions.append((schema, view_name, create_statement))\n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "view_schema = StructType([\n",
    "    StructField(\"Schema\", StringType(), True),\n",
    "    StructField(\"ViewName\", StringType(), True),\n",
    "    StructField(\"CreateStatement\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "views_df = spark.createDataFrame(all_view_definitions, view_schema)\n",
    "\n",
    "# Write the DataFrame to a Hive table\n",
    "views_df.write.mode('overwrite').saveAsTable(\"hive_metastore_view_definitions\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
